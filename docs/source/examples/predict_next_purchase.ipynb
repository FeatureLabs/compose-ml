{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Next Purchase\n",
    "\n",
    "In this example, we will generate labels on online grocery orders provided by Instacart using Compose. The labels can be used to train a machine learning model to predict whether a customer will buy a specific product within the next month.\n",
    "\n",
    "If you plan to run this notebook, you can use the following command at the root directory of the repository.\n",
    "\n",
    "```bash\n",
    "jupyter notebook docs/source/examples/predict-next-purchase/example.ipynb\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import composeml as cp\n",
    "import featuretools as ft\n",
    "from demo.predict_next_purchase import load_sample\n",
    "from evalml import AutoMLSearch\n",
    "from evalml.preprocessing import split_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data hosted [here](https://www.instacart.com/datasets/grocery-shopping-2017) will be downloaded automatically into the `data` module of this notebook unless it already exist. Once the data is in place, we can preview the grocery orders to see how they look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_sample()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## Generate Labels\n",
    "Now with the grocery orders loaded, we are ready to generate labels for our prediction problem.\n",
    "\n",
    "### Create Labeling Function\n",
    "To get started, we define the labeling function that will return whether a customer purchased the product in a given month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bought_product(df, product_name):\n",
    "    return df.product_name.str.contains(product_name).any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct Label Maker\n",
    "\n",
    "With the labeling function, we create the label maker for our prediction problem. To process one month of orders for each customer, we set the `target_entity` to the customer ID and the `window_size` to one month. When window size is set to `1MS`, the window size will end on the first day of the next month. Alias definitions are listed [here](https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = cp.LabelMaker(\n",
    "    target_entity='user_id',\n",
    "    time_index='order_time',\n",
    "    labeling_function=bought_product,\n",
    "    window_size='7d',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search Labels\n",
    "Next, the label maker will search through the data continously to label whether a customer bought bananas in a given month. This happens when we use `LabelMaker.search` and set the `product_name` to bananas. If you are running this code yourself, feel free to expirement with other products (e.g. limes, avocados, etc.) and different time frames!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lt = lm.search(\n",
    "    df.sort_values('order_time'),\n",
    "    minimum_data='3d',\n",
    "    num_examples_per_instance=-1,\n",
    "    product_name='Banana',\n",
    "    gap='3d',\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "lt.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Describe Labels\n",
    "\n",
    "With the generate label times, we can use `LabelTimes.describe` to print out the distribution with the settings and transforms that were used to make these labels. This is useful as a reference for understanding how the labels were generated from raw data. Also, the label distribution is helpful for determining if we have imbalanced labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lt.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Labels\n",
    "\n",
    "Additionally, there are plots available for insight to the labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distribution\n",
    "\n",
    "This plot shows the label distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lt.plot.distribution();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count by Time\n",
    "\n",
    "This plot shows the label distribution across cutoff times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lt.plot.count_by_time();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = ft.EntitySet('instacart')\n",
    "\n",
    "es.entity_from_dataframe(\n",
    "    dataframe=df.reset_index(),\n",
    "    entity_id='order_products',\n",
    "    time_index='order_time',\n",
    "    index='id',\n",
    ")\n",
    "\n",
    "es.normalize_entity(\n",
    "    base_entity_id='order_products',\n",
    "    new_entity_id='orders',\n",
    "    index='order_id',\n",
    "    additional_variables=['user_id'],\n",
    "    make_time_index=False,\n",
    ")\n",
    "\n",
    "es.normalize_entity(\n",
    "    base_entity_id='orders',\n",
    "    new_entity_id='users',\n",
    "    index='user_id',\n",
    "    make_time_index=False,\n",
    ")\n",
    "\n",
    "es.normalize_entity(\n",
    "    base_entity_id='order_products',\n",
    "    new_entity_id='products',\n",
    "    index='product_id',\n",
    "    additional_variables=['aisle_id', 'department_id'],\n",
    "    make_time_index=False,\n",
    ")\n",
    "\n",
    "es.normalize_entity(\n",
    "    base_entity_id='products',\n",
    "    new_entity_id='aisles',\n",
    "    index='aisle_id',\n",
    "    additional_variables=['department_id'],\n",
    "    make_time_index=False,\n",
    ")\n",
    "\n",
    "es.normalize_entity(\n",
    "    base_entity_id='aisles',\n",
    "    new_entity_id='departments',\n",
    "    index='department_id',\n",
    "    make_time_index=False,\n",
    ")\n",
    "\n",
    "es[\"order_products\"][\"department\"].interesting_values = ['produce']\n",
    "es[\"order_products\"][\"product_name\"].interesting_values = ['Banana']\n",
    "es.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, features = ft.dfs(\n",
    "    entityset=es,\n",
    "    target_entity='users',\n",
    "    cutoff_time=lt,\n",
    "    cutoff_time_in_index=True,\n",
    "    include_cutoff_time=False,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = X.pop('bought_product')\n",
    "\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_holdout, y_train, y_holdout = split_data(\n",
    "    X=X,\n",
    "    y=y,\n",
    "    test_size=0.2,\n",
    "    random_state=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl = AutoMLSearch(\n",
    "    problem_type='binary',\n",
    "    objective='f1',\n",
    "    random_state=0,\n",
    ")\n",
    "\n",
    "automl.search(X_train, y_train, data_checks=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl.best_pipeline.describe()\n",
    "automl.best_pipeline.graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_pipeline = automl.best_pipeline.fit(X_train, y_train)\n",
    "\n",
    "score = best_pipeline.score(\n",
    "    X=X_holdout,\n",
    "    y=y_holdout,\n",
    "    objectives=['f1'],\n",
    ")\n",
    "\n",
    "dict(score)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
