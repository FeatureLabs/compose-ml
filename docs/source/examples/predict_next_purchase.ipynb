{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Next Purchase\n",
    "\n",
    "In this example, we build a machine learning application that predicts whether customers will purchase a product within the next shopping period. This application is structured into three important steps:\n",
    "\n",
    "* Prediction Engineering\n",
    "* Feature Engineering\n",
    "* Machine Learning\n",
    "\n",
    "In the first step, we label the historical transactions by using [Compose](https://compose.alteryx.com/). In the second step, we generate the features by using [Featuretools](https://docs.featuretools.com/). In the third step, we search for the best machine learning pipeline by using [EvalML](https://evalml.alteryx.com/). After working through these steps, you will learn how to build machine learning applications for real-world problems like predicting consumer spending. Let's get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/3.7/lib/python3.7/site-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n",
      "/Users/jeff.hernandez/Code/evalml/evalml/pipelines/components/transformers/preprocessing/text_featurization.py:35: RuntimeWarning: No text columns were given to TextFeaturizer, component will have no effect\n",
      "  warnings.warn(\"No text columns were given to TextFeaturizer, component will have no effect\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "from demo.predict_next_purchase import load_sample\n",
    "from evalml import AutoMLSearch\n",
    "from evalml.preprocessing import split_data\n",
    "import composeml as cp\n",
    "import featuretools as ft\n",
    "import matplotlib as mpl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use this historical data of online grocery orders provided by Instacart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>add_to_cart_order</th>\n",
       "      <th>reordered</th>\n",
       "      <th>product_name</th>\n",
       "      <th>aisle_id</th>\n",
       "      <th>department_id</th>\n",
       "      <th>department</th>\n",
       "      <th>user_id</th>\n",
       "      <th>order_time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>120</td>\n",
       "      <td>33120</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>Organic Egg Whites</td>\n",
       "      <td>86</td>\n",
       "      <td>16</td>\n",
       "      <td>dairy eggs</td>\n",
       "      <td>23750</td>\n",
       "      <td>2015-01-11 08:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>120</td>\n",
       "      <td>31323</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>Light Wisconsin String Cheese</td>\n",
       "      <td>21</td>\n",
       "      <td>16</td>\n",
       "      <td>dairy eggs</td>\n",
       "      <td>23750</td>\n",
       "      <td>2015-01-11 08:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>120</td>\n",
       "      <td>1503</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>Low Fat Cottage Cheese</td>\n",
       "      <td>108</td>\n",
       "      <td>16</td>\n",
       "      <td>dairy eggs</td>\n",
       "      <td>23750</td>\n",
       "      <td>2015-01-11 08:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>120</td>\n",
       "      <td>28156</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>Total 0% Nonfat Plain Greek Yogurt</td>\n",
       "      <td>120</td>\n",
       "      <td>16</td>\n",
       "      <td>dairy eggs</td>\n",
       "      <td>23750</td>\n",
       "      <td>2015-01-11 08:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>120</td>\n",
       "      <td>41273</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Broccoli Florets</td>\n",
       "      <td>123</td>\n",
       "      <td>4</td>\n",
       "      <td>produce</td>\n",
       "      <td>23750</td>\n",
       "      <td>2015-01-11 08:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    order_id  product_id  add_to_cart_order  reordered  \\\n",
       "id                                                       \n",
       "0        120       33120                 13          0   \n",
       "1        120       31323                  7          0   \n",
       "2        120        1503                  8          0   \n",
       "3        120       28156                 11          0   \n",
       "4        120       41273                  4          0   \n",
       "\n",
       "                          product_name  aisle_id  department_id  department  \\\n",
       "id                                                                            \n",
       "0                   Organic Egg Whites        86             16  dairy eggs   \n",
       "1        Light Wisconsin String Cheese        21             16  dairy eggs   \n",
       "2               Low Fat Cottage Cheese       108             16  dairy eggs   \n",
       "3   Total 0% Nonfat Plain Greek Yogurt       120             16  dairy eggs   \n",
       "4                     Broccoli Florets       123              4     produce   \n",
       "\n",
       "    user_id          order_time  \n",
       "id                               \n",
       "0     23750 2015-01-11 08:00:00  \n",
       "1     23750 2015-01-11 08:00:00  \n",
       "2     23750 2015-01-11 08:00:00  \n",
       "3     23750 2015-01-11 08:00:00  \n",
       "4     23750 2015-01-11 08:00:00  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = load_sample()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Engineering\n",
    "\n",
    "Note we have two parameters in the prediction problem:\n",
    "\n",
    "* The name of the product.\n",
    "* The length of the shopping period.\n",
    "\n",
    "We can change these parameters to create different prediction problems. For example, will a customer purchase an avocado within the next 3 days or a banana within the next week? These variations can be done by simply tweaking the parameters. This helps us explore different scenarios which is crucial for making better decisions.\n",
    "\n",
    "\n",
    "### Defining the Labeling Process\n",
    "\n",
    "In each shopping period, we will check whether a customer bought a product. Letâ€™s define this as a labeling function with a parameter for the product name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bought_product(ds, product_name):\n",
    "    return ds.product_name.str.contains(product_name).any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Representing the Prediction Problem\n",
    "\n",
    "We will represent the prediction problem using a label maker. This way, we can run searches on the online grocery orders to generate the training examples. This is done by setting the following parameters:\n",
    "\n",
    "* The `target_entity` as the customer, because we want to label orders for each individual customer.\n",
    "* The `labeling_function` as the function we defined previously.\n",
    "* The `time_index` as the order time, because shoppings periods are based on the order time.\n",
    "* The `window_size` as the length of a shopping period. We can tweak this parameter to create variations of the prediction problem. In this case, we will use one week as the length of the shopping period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = cp.LabelMaker(\n",
    "    target_entity='user_id',\n",
    "    time_index='order_time',\n",
    "    labeling_function=bought_product,\n",
    "    window_size='7d',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the Training Examples\n",
    "\n",
    "Now, we can run a search to check whether the product was purchased within shopping periods. This is done using the following parameters:\n",
    "\n",
    "* The online grocery orders sorted by the order time.\n",
    "* The `num_examples_per_instance` to find the number of training examples per customer. In this case, we will search for all existing examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lt = lm.search(\n",
    "    df.sort_values('order_time'),\n",
    "    minimum_data='3d',\n",
    "    num_examples_per_instance=-1,\n",
    "    product_name='Banana',\n",
    "    gap='3d',\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "lt.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We can print out the settings and transforms that were used to make the labels. This is useful as a reference to understand how the labels were made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lt.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These plots show the discrete label distribution and the cumulative count across time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "fig = mpl.pyplot.figure(figsize=(5, 8))\n",
    "ax0 = fig.add_subplot(211)\n",
    "ax1 = mpl.pyplot.subplot(212)\n",
    "fig.tight_layout()\n",
    "\n",
    "lt.plot.distribution(ax=ax0)\n",
    "lt.plot.count_by_time(ax=ax1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Features\n",
    "\n",
    "Now, we are ready for feature engineering. To get started, let's create an entity set to represent the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = ft.EntitySet('instacart')\n",
    "\n",
    "es.entity_from_dataframe(\n",
    "    dataframe=df.reset_index(),\n",
    "    entity_id='order_products',\n",
    "    time_index='order_time',\n",
    "    index='id',\n",
    ")\n",
    "\n",
    "es.normalize_entity(\n",
    "    base_entity_id='order_products',\n",
    "    new_entity_id='orders',\n",
    "    index='order_id',\n",
    "    additional_variables=['user_id'],\n",
    "    make_time_index=False,\n",
    ")\n",
    "\n",
    "es.normalize_entity(\n",
    "    base_entity_id='orders',\n",
    "    new_entity_id='users',\n",
    "    index='user_id',\n",
    "    make_time_index=False,\n",
    ")\n",
    "\n",
    "es.normalize_entity(\n",
    "    base_entity_id='order_products',\n",
    "    new_entity_id='products',\n",
    "    index='product_id',\n",
    "    additional_variables=['aisle_id', 'department_id'],\n",
    "    make_time_index=False,\n",
    ")\n",
    "\n",
    "es.normalize_entity(\n",
    "    base_entity_id='products',\n",
    "    new_entity_id='aisles',\n",
    "    index='aisle_id',\n",
    "    additional_variables=['department_id'],\n",
    "    make_time_index=False,\n",
    ")\n",
    "\n",
    "es.normalize_entity(\n",
    "    base_entity_id='aisles',\n",
    "    new_entity_id='departments',\n",
    "    index='department_id',\n",
    "    make_time_index=False,\n",
    ")\n",
    "\n",
    "es[\"order_products\"][\"department\"].interesting_values = ['produce']\n",
    "es[\"order_products\"][\"product_name\"].interesting_values = ['Banana']\n",
    "es.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's generate the features that correspond to our labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm, fd = ft.dfs(\n",
    "    entityset=es,\n",
    "    target_entity='users',\n",
    "    cutoff_time=lt,\n",
    "    cutoff_time_in_index=True,\n",
    "    include_cutoff_time=False,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "fm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning\n",
    "\n",
    "Now, we can create a machine learning model. Let's extract the labels from the feature matrix and split the data into training and holdout sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = fm.pop('bought_product')\n",
    "splits = split_data(fm, y, test_size=0.2, random_state=0)\n",
    "X_train, X_holdout, y_train, y_holdout = splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model\n",
    "\n",
    "Next, we search for the optimal pipeline by trying out different models on the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl = AutoMLSearch(problem_type='binary', objective='f1', random_state=0)\n",
    "automl.search(X_train, y_train, data_checks=None, show_iteration_plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl.best_pipeline.describe()\n",
    "automl.best_pipeline.graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Model\n",
    "\n",
    "Finally, we score the model performance by evaluating predictions on the holdout set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_pipeline = automl.best_pipeline.fit(X_train, y_train)\n",
    "score = best_pipeline.score(X_holdout, y_holdout, objectives=['f1'])\n",
    "dict(score)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
