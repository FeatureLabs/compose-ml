{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "# Predict Turbofan Degradation\n",
    "\n",
    "In this example, we build a machine learning application that predicts turbofan engine degradation. This application is structured into three important steps:\n",
    "\n",
    "* Prediction Engineering\n",
    "* Feature Engineering\n",
    "* Machine Learning\n",
    "\n",
    "In the first step, we generate our own labels from the data by using [Compose](https://compose.alteryx.com/). In the second step, we generate features for the labels by using [Featuretools](https://docs.featuretools.com/). In the third step, we search for the best machine learning pipeline by using [EvalML](https://evalml.alteryx.com/). \n",
    "After working through these steps, you will learn how to build machine learning applications for real-world problems like predictive maintenance. Let's get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from demo.predict_rul import load_sample\n",
    "from evalml import AutoMLSearch\n",
    "from evalml.preprocessing import split_data\n",
    "import composeml as cp\n",
    "import featuretools as ft\n",
    "import matplotlib as mpl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "We will use a dataset provided by NASA simulating turbofan engine degradation. In this dataset, we have engines which are monitored over time. Each engine had operational settings and sensor measurements recorded for each cycle. The remaining useful life (RUL) is the amount of cycles an engine has left before it needs maintenance. What makes this dataset special is that the engines run all the way until failure, giving us precise RUL information for every engine at every point in time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_sample()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Engineering\n",
    "\n",
    "> Which range is the RUL of a turbofan engine in?\n",
    "\n",
    "In this prediction problem, we want to group the RUL into ranges. Then, predict which range the RUL is in. We can make variations of the ranges to create different prediction problems. For example, the ranges can be manually defined (0 - 150, 150 - 300, etc.) or based on the quartiles from historical observations. These variations can be done by simply binning the RUL. This helps us explore different scenarios which is crucial for making better decisions.\n",
    "\n",
    "### Defining the Labeling Process\n",
    "\n",
    "Let's stary by defining the labeling function of an engine that calculates the RUL. Given that engines run all the way until failure, the RUL is just the remaining number of observations in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rul(ds):\n",
    "    return len(ds) - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "### Representing the Prediction Problem\n",
    "\n",
    "Then, let's represent the prediction problem by creating a label maker with the following parameters:\n",
    "\n",
    "* The `target_entity` as the engine ID, because we want to generate labels for each engine.\n",
    "* The `labeling_function` as the function we defined previously.\n",
    "* The `time_index` as the event time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = cp.LabelMaker(\n",
    "    target_entity='engine_no',\n",
    "    labeling_function=rul,\n",
    "    time_index='time',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "### Finding the Training Examples\n",
    "\n",
    "Now, let's run a search to get the RUL using the following parameters:\n",
    "\n",
    "* The data sorted by the event time.\n",
    "* The `num_examples_per_instance` as the number of training examples to find per engine. In this search, we find up to 20 examples per enigne.\n",
    "* The `minimum_data` as the first number of cycles to skip before labeling starts. In this data sample, turbines generally don't fail before 5 cycles, so we start after 5 cycles.\n",
    "* The `gap` as the number of cycles to place between examples. This is done to cover different points in time of an engine.\n",
    "\n",
    "We can easily tweak these search parameters and generate more training examples as the requirements of our model changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lt = lm.search(\n",
    "    df.sort_values('time'),\n",
    "    num_examples_per_instance=20,\n",
    "    minimum_data=5,\n",
    "    gap=20,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "lt.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "### Continuous Labels\n",
    "\n",
    "The labeling function we defined returns continuous labels which can be used to train a regression model for our predictin problem. Alternatively, there are label transforms available to further process these labels into discrete values. In which case, can be used to train a classification model.\n",
    "\n",
    "#### Describe Labels\n",
    "\n",
    "Let's print out the settings and transforms that were used to make the continuous labels. This is useful as a reference for understanding how the labels were generated from raw data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lt.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These plots show the continuous label distribution and the cumulative count across time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "fig = mpl.pyplot.figure(figsize=(5, 8))\n",
    "ax0 = fig.add_subplot(211)\n",
    "ax1 = mpl.pyplot.subplot(212)\n",
    "fig.tight_layout()\n",
    "\n",
    "lt.plot.distribution(ax=ax0)\n",
    "lt.plot.count_by_time(ax=ax1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "### Discrete Labels\n",
    "\n",
    "Let's further process the labels into discrete values. We divide the RUL into quartile bins to predict which range an engine's RUL will fall in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lt = lt.bin(4, quantiles=True, precision=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "#### Describe Labels\n",
    "\n",
    "Next, let's print out the settings and transforms that were used to make the discrete labels. This time we can see the label distribution which is useful for determining if we have imbalanced labels. Also, we can see that the label type changed from continuous to discrete and the binning transform used in the previous step is included below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lt.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These plots show the discrete label distribution and the cumulative count across time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "fig = mpl.pyplot.figure(figsize=(5, 8))\n",
    "ax0 = fig.add_subplot(211)\n",
    "ax1 = mpl.pyplot.subplot(212)\n",
    "fig.tight_layout()\n",
    "\n",
    "lt.plot.distribution(ax=ax0)\n",
    "lt.plot.count_by_time(ax=ax1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "## Generate Features\n",
    "\n",
    "Now, we are ready to generate features for our prediction problem.\n",
    "\n",
    "### Create Entity Set\n",
    "\n",
    "To get started, let's create an entity set for the observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = ft.EntitySet('observations')\n",
    "\n",
    "es.entity_from_dataframe(\n",
    "    dataframe=df.reset_index(),\n",
    "    entity_id='recordings',\n",
    "    index='id',\n",
    "    time_index='time',\n",
    ")\n",
    "\n",
    "es.normalize_entity(\n",
    "    base_entity_id='recordings',\n",
    "    new_entity_id='engines',\n",
    "    index='engine_no',\n",
    ")\n",
    "\n",
    "es.normalize_entity(\n",
    "    base_entity_id='recordings',\n",
    "    new_entity_id='cycles',\n",
    "    index='time_in_cycles',\n",
    ")\n",
    "\n",
    "es.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "### Create Feature Matrix\n",
    "\n",
    "Let's generate the features that correspond to our labels. To do this, we set the engines as the target entity and our labels as the cutoff time. This way the features are calculated only using data up to the cutoff time of each label. Notice that the output from Compose integrates easily with Featuretools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm, fd = ft.dfs(\n",
    "    entityset=es,\n",
    "    target_entity='engines',\n",
    "    agg_primitives=['sum'],\n",
    "    trans_primitives=[],\n",
    "    cutoff_time=lt,\n",
    "    cutoff_time_in_index=True,\n",
    "    include_cutoff_time=False,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "fm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "## Machine Learning\n",
    "\n",
    "Now, we are ready to create a machine learning model for our prediction problem.\n",
    "\n",
    "### Split Data\n",
    "\n",
    "Let's extract the labels from the feature matrix and split the data into training and holdout sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = fm.pop('rul').cat.codes\n",
    "splits = split_data(fm, y, test_size=0.2, random_state=0)\n",
    "X_train, X_holdout, y_train, y_holdout = splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "### Train Model\n",
    "\n",
    "Next, we search for the optimal pipeline by trying out different models on the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl = AutoMLSearch(problem_type='multiclass', objective='f1_macro')\n",
    "automl.search(X_train, y_train, data_checks=None, show_iteration_plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl.best_pipeline.describe()\n",
    "automl.best_pipeline.graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "### Test Model\n",
    "\n",
    "Finally, we score the model performance by evaluating predictions on the holdout set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_pipeline = automl.best_pipeline.fit(X_train, y_train)\n",
    "score = best_pipeline.score(X_holdout, y_holdout, objectives=['f1_macro'])\n",
    "dict(score)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
