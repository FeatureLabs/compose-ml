{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "# Predict Remaining Useful Life\n",
    "\n",
    "\n",
    "In this example, we will generate labels using Compose on data provided by NASA simulating turbofan engine degradation. Then, the labels are used to generate features and train a machine learning model to predict the Remaining Useful Life (RUL) of an engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from demo.predict_rul import load_sample\n",
    "from evalml import AutoMLSearch\n",
    "from evalml.preprocessing import split_data\n",
    "import composeml as cp\n",
    "import featuretools as ft\n",
    "import matplotlib as mpl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "## Load Data\n",
    "\n",
    "In this dataset, we have engines which are monitored over time. Each engine had operational settings and sensor measurements recorded for each cycle. The Remaining Useful Life (RUL) is the amount of cycles an engine has left before it needs maintenance. What makes this dataset special is that the engines run all the way until failure, giving us precise RUL information for every engine at every point in time. \n",
    "\n",
    "Let's start by previewing the data to get an idea on how to observations look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_sample()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "## Generate Labels\n",
    "\n",
    "Now with the observations loaded, we are ready to generate the labels for our prediction problem.\n",
    "\n",
    "### Define Labeling Function\n",
    "We first define the labeling function that returns the RUL given the remaining observations of an engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remaining_useful_life(df):\n",
    "    return len(df) - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "### Create Label Maker\n",
    "\n",
    "Next, we create the label maker. To process the RUL for each engine, the engines are set as the taget entity. The window size is set as the total observation size for each engine by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = cp.LabelMaker(\n",
    "    target_entity='engine_no',\n",
    "    time_index='time',\n",
    "    labeling_function=remaining_useful_life,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "### Search Labels\n",
    "\n",
    "Let's imagine we want to make predictions on turbines that are up and running. Turbines in general don't fail before 5 cycles, so we will make labels only for engines that reach at least 5 cycles. To do this, the parameter `minimum_data` is set as 5. The parameter `gap` will apply the labeling function every 20 cycles. The parameter `num_examples_per_instance` will allow up to 20 examples per engine. We can easily tweak these parameter as the requirements of our model changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lt = lm.search(\n",
    "    df.sort_values('time'),\n",
    "    num_examples_per_instance=20,\n",
    "    minimum_data=5,\n",
    "    gap=20,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "lt.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "### Continuous Labels\n",
    "\n",
    "The labeling function we defined returns continuous labels which can be used to train a regression model for our predictin problem. Alternatively, there are label transforms available to further process these labels into discrete values. In which case, can be used to train a classification model.\n",
    "\n",
    "#### Describe Labels\n",
    "\n",
    "Let's print out the settings and transforms that were used to make the continuous labels. This is useful as a reference for understanding how the labels were generated from raw data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lt.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These plots show the continuous label distribution and the cumulative count across time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "fig = mpl.pyplot.figure(figsize=(5, 8))\n",
    "ax0 = fig.add_subplot(211)\n",
    "ax1 = mpl.pyplot.subplot(212)\n",
    "fig.tight_layout()\n",
    "\n",
    "lt.plot.distribution(ax=ax0)\n",
    "lt.plot.count_by_time(ax=ax1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "### Discrete Labels\n",
    "\n",
    "Let's further process the labels into discrete values. We divide the RUL into quartile bins to predict which range an engine's RUL will fall in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lt = lt.bin(4, quantiles=True, precision=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "#### Describe Labels\n",
    "\n",
    "Next, let's print out the settings and transforms that were used to make the discrete labels. This time we can see the label distribution which is useful for determining if we have imbalanced labels. Also, we can see that the label type changed from continuous to discrete and the binning transform used in the previous step is included below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lt.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These plots show the discrete label distribution and the cumulative count across time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "fig = mpl.pyplot.figure(figsize=(5, 8))\n",
    "ax0 = fig.add_subplot(211)\n",
    "ax1 = mpl.pyplot.subplot(212)\n",
    "fig.tight_layout()\n",
    "\n",
    "lt.plot.distribution(ax=ax0)\n",
    "lt.plot.count_by_time(ax=ax1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "## Generate Features\n",
    "\n",
    "Now, we are ready to generate features for our prediction problem.\n",
    "\n",
    "### Create Entity Set\n",
    "\n",
    "To get started, let's create an entity set for the observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = ft.EntitySet('observations')\n",
    "\n",
    "es.entity_from_dataframe(\n",
    "    dataframe=df.reset_index(),\n",
    "    entity_id='recordings',\n",
    "    index='id',\n",
    "    time_index='time',\n",
    ")\n",
    "\n",
    "es.normalize_entity(\n",
    "    base_entity_id='recordings',\n",
    "    new_entity_id='engines',\n",
    "    index='engine_no',\n",
    ")\n",
    "\n",
    "es.normalize_entity(\n",
    "    base_entity_id='recordings',\n",
    "    new_entity_id='cycles',\n",
    "    index='time_in_cycles',\n",
    ")\n",
    "\n",
    "es.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "### Create Feature Matrix\n",
    "\n",
    "Let's generate the features that correspond to our labels. To do this, we set the engines as the target entity and our labels as the cutoff time. This way the features are calculated only using data up to the cutoff time of each label. Notice that the output from Compose integrates easily with Featuretools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm, fd = ft.dfs(\n",
    "    entityset=es,\n",
    "    target_entity='engines',\n",
    "    agg_primitives=['sum'],\n",
    "    trans_primitives=[],\n",
    "    cutoff_time=lt,\n",
    "    cutoff_time_in_index=True,\n",
    "    include_cutoff_time=False,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "fm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "## Machine Learning\n",
    "\n",
    "Now, we are ready to create a machine learning model for our prediction problem.\n",
    "\n",
    "### Split Data\n",
    "\n",
    "Let's extract the labels from the feature matrix and split the data into training and holdout sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = fm.pop('remaining_useful_life').cat.codes\n",
    "splits = split_data(fm, y, test_size=0.2, random_state=0)\n",
    "X_train, X_holdout, y_train, y_holdout = splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "### Train Model\n",
    "\n",
    "Next, we search for the optimal pipeline by trying out different models on the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl = AutoMLSearch(problem_type='multiclass', objective='f1_macro')\n",
    "automl.search(X_train, y_train, data_checks=None, show_iteration_plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl.best_pipeline.describe()\n",
    "automl.best_pipeline.graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "### Test Model\n",
    "\n",
    "Finally, we score the model performance by evaluating predictions on the holdout set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_pipeline = automl.best_pipeline.fit(X_train, y_train)\n",
    "score = best_pipeline.score(X_holdout, y_holdout, objectives=['f1_macro'])\n",
    "dict(score)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
