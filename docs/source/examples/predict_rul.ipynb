{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "# Predict Turbofan Degradation\n",
    "\n",
    "In this example, we build a machine learning application that predicts turbofan engine degradation. This application is structured into three important steps:\n",
    "\n",
    "* Prediction Engineering\n",
    "* Feature Engineering\n",
    "* Machine Learning\n",
    "\n",
    "In the first step, we generate our own labels from the data by using [Compose](https://compose.alteryx.com/). In the second step, we generate features for the labels by using [Featuretools](https://docs.featuretools.com/). In the third step, we search for the best machine learning pipeline by using [EvalML](https://evalml.alteryx.com/). \n",
    "After working through these steps, you will learn how to build machine learning applications for real-world problems like predictive maintenance. Let's get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from demo.predict_rul import load_sample\n",
    "from matplotlib.pyplot import subplots\n",
    "import composeml as cp\n",
    "import featuretools as ft\n",
    "import evalml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "We will use a dataset provided by NASA simulating turbofan engine degradation. In this dataset, we have engines which are monitored over time. Each engine had operational settings and sensor measurements recorded for each cycle. The remaining useful life (RUL) is the amount of cycles an engine has left before it needs maintenance. What makes this dataset special is that the engines run all the way until failure, giving us precise RUL information for every engine at every point in time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_sample()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Engineering\n",
    "\n",
    "> Which range is the RUL of a turbofan engine in?\n",
    "\n",
    "In this prediction problem, we want to group the RUL into ranges. Then, predict which range the RUL is in. We can make variations of the ranges to create different prediction problems. For example, the ranges can be manually defined (0 - 150, 150 - 300, etc.) or based on the quartiles from historical observations. These variations can be done by simply binning the RUL. This helps us explore different scenarios which is crucial for making better decisions.\n",
    "\n",
    "### Defining the Labeling Process\n",
    "\n",
    "Let's stary by defining the labeling function of an engine that calculates the RUL. Given that engines run all the way until failure, the RUL is just the remaining number of observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rul(ds):\n",
    "    return len(ds) - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "### Representing the Prediction Problem\n",
    "\n",
    "Then, let's represent the prediction problem by creating a label maker with the following parameters:\n",
    "\n",
    "* The `target_entity` as the engine ID, because we want to generate labels for each engine.\n",
    "* The `labeling_function` as the function we defined previously.\n",
    "* The `time_index` as the event time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = cp.LabelMaker(\n",
    "    target_entity='engine_no',\n",
    "    labeling_function=rul,\n",
    "    time_index='time',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "### Finding the Training Examples\n",
    "\n",
    "Now, let's run a search to get the RUL using the following parameters:\n",
    "\n",
    "* The historical data sorted by the event time.\n",
    "* The `num_examples_per_instance` as the number of training examples to find per engine. In this search, we find up to 20 examples per enigne.\n",
    "* The `minimum_data` as the first number of cycles to skip before the labeling starts. In this data sample, turbines generally don't fail before 5 cycles, so we start after 5 cycles.\n",
    "* The `gap` as the number of cycles to place between examples. This is done to cover different points in time of an engine.\n",
    "\n",
    "We can easily tweak the search parameters and generate more training examples as the requirements of our model changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lt = lm.search(\n",
    "    df.sort_values('time'),\n",
    "    num_examples_per_instance=20,\n",
    "    minimum_data=5,\n",
    "    gap=20,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "lt.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "The output from the search is a label times table with three columns:\n",
    "\n",
    "* The engine ID associated to the RUL.\n",
    "* The point in time of the engine when we calculated the RUL. This is also known as a cutoff time for building features. Only data that existed beforehand is valid to use for making predictions about the outcome.\n",
    "* The value of the RUL. This is calculated by our labeling function.\n",
    "\n",
    "At this point, we only have continuous values of the RUL. As a helpul reference, we can print out the search settings that were used to generate the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lt.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also get a better look at the values by plotting the distribution and the cumulative count across time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "fig, ax = subplots(nrows=2, ncols=1, figsize=(6, 8))\n",
    "lt.plot.distribution(ax=ax[0])\n",
    "lt.plot.count_by_time(ax=ax[1])\n",
    "fig.tight_layout(pad=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "Next, let's bin the values into ranges for discrete labels. We can instantly create variations of the prediction problem by exploring different ranges without running the search again for the training examples. In this case, we will just use ranges based on the quartiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lt = lt.bin(4, quantiles=True, precision=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "When we print out the settings again, we can see that the description of the labels has been updated and reflects the recent changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lt.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the new label distribution and the cumulative count across time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "fig, ax = subplots(nrows=2, ncols=1, figsize=(6, 8))\n",
    "lt.plot.distribution(ax=ax[0])\n",
    "lt.plot.count_by_time(ax=ax[1])\n",
    "fig.tight_layout(pad=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "## Generate Features\n",
    "\n",
    "Now, we are ready to generate features for our prediction problem.\n",
    "\n",
    "### Create Entity Set\n",
    "\n",
    "To get started, let's create an entity set for the observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = ft.EntitySet('observations')\n",
    "\n",
    "es.entity_from_dataframe(\n",
    "    dataframe=df.reset_index(),\n",
    "    entity_id='recordings',\n",
    "    index='id',\n",
    "    time_index='time',\n",
    ")\n",
    "\n",
    "es.normalize_entity(\n",
    "    base_entity_id='recordings',\n",
    "    new_entity_id='engines',\n",
    "    index='engine_no',\n",
    ")\n",
    "\n",
    "es.normalize_entity(\n",
    "    base_entity_id='recordings',\n",
    "    new_entity_id='cycles',\n",
    "    index='time_in_cycles',\n",
    ")\n",
    "\n",
    "es.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "### Create Feature Matrix\n",
    "\n",
    "Let's generate the features that correspond to our labels. To do this, we set the engines as the target entity and our labels as the cutoff time. This way the features are calculated only using data up to the cutoff time of each label. Notice that the output from Compose integrates easily with Featuretools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm, fd = ft.dfs(\n",
    "    entityset=es,\n",
    "    target_entity='engines',\n",
    "    agg_primitives=['sum'],\n",
    "    trans_primitives=[],\n",
    "    cutoff_time=lt,\n",
    "    cutoff_time_in_index=True,\n",
    "    include_cutoff_time=False,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "fm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "## Machine Learning\n",
    "\n",
    "Now, we are ready to create a machine learning model for our prediction problem.\n",
    "\n",
    "### Split Data\n",
    "\n",
    "Let's extract the labels from the feature matrix and split the data into training and holdout sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = fm.pop('rul').cat.codes\n",
    "splits = evalml.preprocessing.split_data(fm, y, test_size=0.2, random_state=0)\n",
    "X_train, X_holdout, y_train, y_holdout = splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "### Train Model\n",
    "\n",
    "Next, we search for the optimal pipeline by trying out different models on the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl = evalml.AutoMLSearch(problem_type='multiclass', objective='f1_macro')\n",
    "automl.search(X_train, y_train, data_checks=None, show_iteration_plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl.best_pipeline.describe()\n",
    "automl.best_pipeline.graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "### Test Model\n",
    "\n",
    "Finally, we score the model performance by evaluating predictions on the holdout set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_pipeline = automl.best_pipeline.fit(X_train, y_train)\n",
    "score = best_pipeline.score(X_holdout, y_holdout, objectives=['f1_macro'])\n",
    "dict(score)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
