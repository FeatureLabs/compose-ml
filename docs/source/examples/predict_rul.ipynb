{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "=============================\n",
    "Predict Remaining Useful Life\n",
    "=============================\n",
    "In this example, we will generate labels using Compose on data provided by NASA simulating turbofan engine degradation. Then, the labels are used to generate features and train a machine learning model to predict the Remaining Useful Life (RUL) of an engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import composeml as cp\n",
    "import featuretools as ft\n",
    "from demo.predict_rul import load_sample\n",
    "from evalml import AutoMLSearch\n",
    "from evalml.preprocessing import split_data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "Load Data\n",
    "=========\n",
    "In this dataset, we have engines (:code:`engine_no`) which are monitored over time (:code:`time_in_cycles`). Each engine had :code:`operational_settings` and :code:`sensor_measurements` recorded for each cycle. The **Remaining Useful Life** (RUL) is the amount of cycles an engine has left before it needs maintenance. What makes this dataset special is that the engines run all the way until failure, giving us precise RUL information for every engine at every point in time.\n",
    "\n",
    "You can download the data directly from NASA `here <https://ti.arc.nasa.gov/c/6/>`_. After downloading the data, you can set the :code:`file` parameter as an absolute path to :code:`train_FD004.txt`. With the file in place, we preview the data to get an idea on how to observations look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_sample()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "Generate Labels\n",
    "===============\n",
    "Now with the observations loaded, we are ready to generate labels for our prediction problem.\n",
    "\n",
    "Define Labeling Function\n",
    "------------------------\n",
    "To get started, we define the labeling function that will return the RUL given the remaining observations of an engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remaining_useful_life(df):\n",
    "    return len(df) - 1"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "Create Label Maker\n",
    "------------------\n",
    "With the labeling function, we create the label maker for our prediction problem. To process the RUL for each engine, we set the :code:`target_entity` to the engine number. By default, the :code:`window_size` is set to the total observation size to contain the remaining observations for each engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = cp.LabelMaker(\n",
    "    target_entity='engine_no',\n",
    "    time_index='time',\n",
    "    labeling_function=remaining_useful_life,\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "Search Labels\n",
    "-------------\n",
    "Let's imagine we want to make predictions on turbines that are up and running. Turbines in general don't fail before 120 cycles, so we will only make labels for engines that reach at least 100 cycles. To do this, the :code:`minimum_data` parameter is set to 100. Using Compose, we can easily tweak this parameter as the requirements of our model changes. Additionally, we set :code:`gap` to one to create labels on every cycle and limit the search to 10 examples for each engine.\n",
    "\n",
    ".. seealso::\n",
    "    For more details on how the label maker works, see :doc:`/main_concepts`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lt = lm.search(\n",
    "    df.sort_values('time'),\n",
    "    num_examples_per_instance=20,\n",
    "    minimum_data=5,\n",
    "    gap=20,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "lt.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "Continuous Labels\n",
    "-----------------\n",
    "The labeling function we defined returns continuous labels which can be used to train a regression model for our predictin problem. Alternatively, there are label transforms available to further process these labels into discrete values. In which case, can be used to train a classification model.\n",
    "\n",
    "Describe Labels\n",
    "~~~~~~~~~~~~~~~\n",
    "Let's print out the settings and transforms that were used to make the continuous labels. This is useful as a reference for understanding how the labels were generated from raw data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lt.describe()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "Let's plot the labels to get additional insight of the RUL.\n",
    "\n",
    "Label Distribution\n",
    "~~~~~~~~~~~~~~~~~~\n",
    "This plot shows the continuous label distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lt.plot.distribution();"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "Discrete Labels\n",
    "---------------\n",
    "\n",
    "Let's further process the labels into discrete values. We divide the RUL into quartile bins to predict which range an engine's RUL will fall in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lt = lt.bin(4, quantiles=True, precision=0)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "Describe Labels\n",
    "~~~~~~~~~~~~~~~\n",
    "\n",
    "Next, let's print out the settings and transforms that were used to make the discrete labels. This time we can see the label distribution which is useful for determining if we have imbalanced labels. Also, we can see that the label type changed from continuous to discrete and the binning transform used in the previous step is included below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lt.describe()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "Let's plot the labels to get additional insight of the RUL.\n",
    "\n",
    "Label Distribution\n",
    "~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "This plot shows the discrete label distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lt.plot.distribution();"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "Count by Time\n",
    "~~~~~~~~~~~~~\n",
    "This plot shows the label count accumulated across cutoff times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lt.plot.count_by_time();"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "Generate Features\n",
    "=================\n",
    "Now, we are ready to generate features for our prediction problem.\n",
    "\n",
    "Create Entity Set\n",
    "-----------------\n",
    "To get started, let's create an :class:`EntitySet` for the observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = ft.EntitySet('observations')\n",
    "\n",
    "es.entity_from_dataframe(\n",
    "    dataframe=df.reset_index(),\n",
    "    entity_id='recordings',\n",
    "    index='id',\n",
    "    time_index='time',\n",
    ")\n",
    "\n",
    "es.normalize_entity(\n",
    "    base_entity_id='recordings',\n",
    "    new_entity_id='engines',\n",
    "    index='engine_no',\n",
    ")\n",
    "\n",
    "es.normalize_entity(\n",
    "    base_entity_id='recordings',\n",
    "    new_entity_id='cycles',\n",
    "    index='time_in_cycles',\n",
    ")\n",
    "\n",
    "es.plot()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "Create Feature Matrix\n",
    "---------------------\n",
    "To simplify the calculation for the feature matrix, we only use 20 percent of the labels."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "lt = lt.sample(frac=.2, random_state=0)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "Let's generate features that correspond to the labels. To do this, we set the :code:`target_entity` to engines and the :code:`cutoff_time` to our labels so that the features are calculated for each engine only using data up to and including the cutoff time of each label. Notice that the output of Compose integrates easily with Featuretools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, features = ft.dfs(\n",
    "    entityset=es,\n",
    "    target_entity='engines',\n",
    "    agg_primitives=['sum'],\n",
    "    trans_primitives=[],\n",
    "    cutoff_time=lt,\n",
    "    cutoff_time_in_index=True,\n",
    "    include_cutoff_time=False,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "Machine Learning\n",
    "================\n",
    "Now, we are ready to create a machine learning model for our prediction problem.\n",
    "\n",
    "Preprocess Features\n",
    "-------------------\n",
    "Let's extract the labels from the feature matrix and fill any missing values with zeros. Additionally, the categorical features are one-hot encoded."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "Split Labels and Features\n",
    "-------------------------\n",
    "Then, we split the labels and features into training and holdout sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = X.pop('remaining_useful_life').cat.codes\n",
    "datasets = split_data(X, y, test_size=0.2, random_state=0)\n",
    "X_train, X_holdout, y_train, y_holdout = datasets"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "Train Model\n",
    "-----------\n",
    "Next, we train a random forest classifer on the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl = AutoMLSearch(problem_type='multiclass', objective='f1_macro')\n",
    "automl.search(X_train, y_train, data_checks=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl.best_pipeline.describe()\n",
    "automl.best_pipeline.graph()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "Test Model\n",
    "----------\n",
    "Lastly, we score the model performance by evaluating predictions on the holdout set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_pipeline = automl.best_pipeline.fit(X_train, y_train)\n",
    "score = best_pipeline.score(X_holdout, y_holdout, objectives=['f1_macro'])\n",
    "dict(score)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
